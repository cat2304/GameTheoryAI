# 德州扑克 AI 机器人系统架构设计

## 1. 概述

本文档旨在详细描述德州扑克 AI 机器人的系统架构。该机器人旨在通过模拟器（如 MuMu 模拟器）进行游戏，利用视觉识别获取游戏状态，通过 AI 模型进行决策，并模拟用户操作执行动作。系统将提供 API 接口，并包含牌桌管理、内容管理和决策管理等功能。

## 2. 系统目标

*   **自动化游戏**：能够在无人干预的情况下，在模拟器中自动进行德州扑克游戏。
*   **智能决策**：集成 `pokerllm/pokerbench` 模型或类似模型，实现高水平的扑克决策。
*   **模块化设计**：各功能模块解耦，易于开发、测试和维护。
*   **可扩展性**：方便未来功能升级和新算法集成。
*   **API 接口**：提供标准化的 API 接口，方便外部系统调用和管理。

## 3. 系统架构图

```mermaid
graph TD
    A[用户/外部系统] -->|API 请求| B(API 接口模块);
    B --> C{任务调度与管理模块};
    C --> D[视觉识别模块];
    D -- 游戏截图 --> E(图像处理与状态解析);
    E -- 结构化牌局信息 --> C;
    C -- 当前牌局状态 --> F[决策模块 (PokerLLM/PokerBench)];
    F -- 决策指令 --> C;
    C -- 执行指令 --> G[动作执行模块 (ADB)];
    G -- 操作模拟器界面 --> H(MuMu 模拟器);
    H -- 游戏界面变化 --> D;
    C --> I[数据存储模块 (牌局记录、模型数据等)];
    J[牌桌管理模块] --> C;
    K[内容管理模块] --> C;
    L[决策管理模块] --> F;
```

*(注意：上述 Mermaid 图谱仅为示意，实际渲染效果取决于查看环境)*

## 4. 模块详细设计

### 4.1 视觉识别模块

*   **功能**：负责从 MuMu 模拟器的游戏界面截取屏幕图像，并识别出关键游戏信息。
*   **子模块**：
    *   **ADB 截图子模块**：通过 Python 调用 ADB (Android Debug Bridge) 命令，定时或按需截取模拟器屏幕。
        *   技术选型：Python `subprocess` 模块执行 `adb shell screencap -p /sdcard/screen.png` 及 `adb pull /sdcard/screen.png local_path`。
    *   **图像预处理子模块**：对截图进行灰度化、二值化、降噪、边缘检测等操作，以提高识别准确率。
        *   技术选型：OpenCV-Python。
    *   **元素定位与识别子模块**：
        *   **卡牌识别**：识别玩家手牌、公共牌的点数和花色。可采用模板匹配（针对固定牌面样式）或基于深度学习的目标检测模型（如 YOLOv5/v8，需要训练卡牌数据集）。
        *   **筹码识别**：识别玩家的筹码数量、底池大小等。可能需要 OCR 技术或结合位置信息进行模板匹配。
        *   **玩家位置与状态识别**：识别当前行动玩家、各玩家位置（庄家、大小盲等）、玩家动作（下注、跟注、弃牌等）。可基于界面布局和特定图标进行识别。
        *   **按钮识别**：识别可操作按钮（如“跟注”、“加注”、“弃牌”）及其位置，用于后续的动作执行。
*   **输出**：结构化的牌局信息，例如：
    ```json
    {
      "my_hand": ["As", "Kd"],
      "community_cards": ["Qh", "Js", "Td"],
      "pot_size": 150,
      "current_player": "Hero",
      "players": [
        {"name": "Player1", "stack": 850, "position": "SB", "last_action": "BET", "bet_amount": 50},
        {"name": "Hero", "stack": 950, "position": "BB", "last_action": null, "bet_amount": 0}
      ],
      "available_actions": ["CALL", "RAISE", "FOLD"]
    }
    ```

### 4.2 决策模块

*   **功能**：根据视觉识别模块提供的当前牌局状态，结合预设策略或 AI 模型，生成最优决策。
*   **核心**：集成 `pokerllm/pokerbench` 模型。
    *   **输入**：符合 `pokerllm/pokerbench` 模型要求的自然语言描述或结构化数据。需要一个转换层将视觉识别模块的输出转换为模型输入格式。
        *   例如，将结构化的牌局信息转换为类似 `pokerllm/pokerbench` 数据集中的 `instruction` 格式。
    *   **模型调用**：通过 Python 加载并调用 `pokerllm/pokerbench` 提供的模型进行推理。
    *   **输出**：模型的决策建议，如 "CALL", "RAISE 100", "FOLD"。
*   **备选/辅助策略**：
    *   可配置基于规则的简单策略用于特定场景或作为模型故障时的备用。
    *   考虑集成其他开源的德州扑克 AI 算法库作为补充。

### 4.3 动作执行模块

*   **功能**：接收决策模块生成的指令，并通过 ADB 模拟用户在模拟器界面上的操作。
*   **技术选型**：Python `subprocess` 模块执行 ADB 命令。
*   **主要操作**：
    *   **点击 (Tap)**：`adb shell input tap x y`，根据视觉识别模块定位到的按钮坐标执行点击。
    *   **输入文本 (Input Text)**：`adb shell input text 'string'`，用于输入下注金额等（如果界面支持）。
    *   **滑动 (Swipe)**：`adb shell input swipe x1 y1 x2 y2 duration_ms`，用于可能的滑动操作。
    *   **按键事件 (Key Event)**：`adb shell input keyevent <keycode>`，用于模拟特定按键。
*   **坐标管理**：需要精确管理不同分辨率和界面的按钮坐标。可以考虑在初始化阶段进行一次坐标校准或使用相对坐标。

### 4.4 API 接口模块

*   **功能**：提供 RESTful API 接口，供外部系统调用，实现对机器人的控制、状态查询和数据获取。
*   **技术选型**：Python Web 框架，如 Flask 或 FastAPI。
*   **主要接口**：
    *   `/start_bot` (POST): 启动机器人。
    *   `/stop_bot` (POST): 停止机器人。
    *   `/get_status` (GET): 获取机器人当前状态（如：空闲、游戏中、错误）。
    *   `/get_game_state` (GET): 获取当前牌局的详细信息。
    *   `/get_decision_log` (GET): 获取历史决策记录。
    *   `/configure_bot` (POST): 配置机器人参数（如：决策模型、游戏策略）。
*   **安全性**：考虑 API 认证和授权机制。

### 4.5 任务调度与管理模块

*   **功能**：作为系统的中枢，协调各个模块的工作流程，管理任务队列，处理模块间的通信和数据流转。
*   **核心逻辑**：
    1.  接收 API 指令或内部触发事件。
    2.  调用视觉识别模块获取牌局状态。
    3.  将牌局状态传递给决策模块。
    4.  接收决策模块的指令。
    5.  调用动作执行模块执行操作。
    6.  记录日志和牌局数据。
    7.  处理异常和错误。
*   **技术实现**：Python 主控制脚本，可能使用多线程/异步处理来避免阻塞。

### 4.6 数据存储模块

*   **功能**：存储系统运行过程中的各种数据。
*   **存储内容**：
    *   **牌局记录**：详细记录每手牌的流程、玩家动作、AI 决策等。
    *   **模型数据**：存储 `pokerllm/pokerbench` 模型文件及相关配置。
    *   **配置信息**：系统配置、用户偏好设置等。
    *   **日志文件**：系统运行日志、错误日志。
*   **技术选型**：
    *   简单场景：JSON 文件、CSV 文件、SQLite 数据库。
    *   复杂场景或需要高效查询：关系型数据库 (如 PostgreSQL, MySQL) 或 NoSQL 数据库 (如 MongoDB)。

### 4.7 牌桌管理模块

*   **功能**：管理机器人参与的牌桌信息，如同时运行的牌桌数量、特定牌桌的配置等。
*   **接口**：通过 API 模块暴露给用户。

### 4.8 内容管理模块

*   **功能**：管理与机器人相关的内容，如AI模型的版本、策略配置、视觉识别的模板图片库等。
*   **接口**：通过 API 模块暴露给用户。

### 4.9 决策管理模块

*   **功能**：管理决策逻辑，允许用户选择不同的决策模型、调整模型参数或配置自定义规则。
*   **接口**：通过 API 模块暴露给用户，并与决策模块紧密集成。

## 5. 技术栈总结

*   **主要编程语言**：Python
*   **核心库/框架**：
    *   **视觉识别**：OpenCV-Python, Pillow。可选：YOLO (PyTorch/TensorFlow)
    *   **模拟器交互**：ADB (通过 Python `subprocess`)
    *   **决策模型**：Hugging Face Transformers (如果 `pokerllm/pokerbench` 基于此) 或模型本身的 Python API。
    *   **API 服务**：Flask 或 FastAPI。
    *   **数据存储**：SQLite, JSON/CSV (基础)，可选 PostgreSQL/MySQL/MongoDB。
*   **开发环境**：Linux (推荐用于 ADB 和 Python 开发)
*   **模拟器**：MuMu 模拟器

## 6. 开发流程与注意事项

1.  **环境搭建**：安装 Python、ADB、OpenCV 及其他依赖库，配置 MuMu 模拟器并开启开发者模式和 USB 调试。
2.  **模块化开发**：优先开发核心模块（视觉识别、决策、动作执行），并进行单元测试。
3.  **视觉识别调优**：卡牌和关键元素的识别是系统的瓶颈之一，需要投入较多时间进行模板制作/模型训练和参数调优，确保在不同光照、角度和模拟器皮肤下的鲁棒性。
4.  **决策模型集成**：仔细阅读 `pokerllm/pokerbench` 的文档，理解其输入输出格式和调用方式。
5.  **坐标适配**：模拟器分辨率和游戏界面布局可能变化，需要设计灵活的坐标定位机制。
6.  **异常处理**：充分考虑各种异常情况，如模拟器卡顿、网络延迟、界面元素未找到、决策模型错误等，并设计相应的重试或恢复机制。
7.  **日志记录**：详细记录关键步骤的日志，方便调试和问题追踪。
8.  **安全性**：如果对外提供 API，务必考虑安全措施。

## 7. 后续工作

*   根据此架构设计，细化各模块的接口定义和数据结构。
*   制定详细的开发计划和任务分配。
*   逐步实现并测试各个模块。


