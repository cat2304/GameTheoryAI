import os
import torch
from rfdetr import RFDETRBase

def main():
    # åœ¨è„šæœ¬å¼€å§‹æ—¶å°±è®¾ç½®ç¯å¢ƒå˜é‡ - å½»åº•ç¦ç”¨MPS
    os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
    # ä½¿ç”¨ç¯å¢ƒå˜é‡ç¦ç”¨MPSè®¾å¤‡
    os.environ["PYTORCH_NO_MPS"] = "1"
    
    # ç¡®ä¿ä¸ä½¿ç”¨MPSè®¾å¤‡
    device = torch.device('cpu')
    
    torch.cuda.empty_cache()
    # ç¦ç”¨å¤šè¿›ç¨‹
    torch.multiprocessing.set_start_method('spawn', force=True)

    # æ•°æ®è·¯å¾„
    DATASET_DIR = "dataset"
    OUTPUT_DIR = "data/output"
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    model = RFDETRBase(
        encoder="dinov2_windowed_small",
        resolution=392,
        multi_scale=False,
        expanded_scales=False,
        dec_layers=2,
        dim_feedforward=1024,
        hidden_dim=192,
        sa_nheads=4,
        ca_nheads=8,
        num_queries=100,
        pretrain_weights=None,
        force_no_pretrain=True
    )

    print(f"ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œæ•°æ®é›†è·¯å¾„: {DATASET_DIR}")
    model.train(
        dataset_dir=DATASET_DIR,
        epochs=1,
        batch_size=2,
        grad_accum_steps=8,
        lr=1e-4,
        output_dir=OUTPUT_DIR,
        num_workers=0,      # âœ… å…³é”®ç‚¹ï¼šmacOS å¿…é¡»ä¸º 0
        device="cpu"        # âœ… ä¸ç”¨ GPU æ—¶éœ€æŒ‡å®š
    )

    # ç›´æ¥ä¿å­˜PyTorchæ¨¡å‹
    print("ğŸ“¦ ä¿å­˜PyTorchæ¨¡å‹...")
    torch_path = os.path.join(OUTPUT_DIR, "rf-detr.pth")
    
    # ç›´æ¥ä¿å­˜æ•´ä¸ªæ¨¡å‹è€Œä¸æ˜¯state_dict
    torch.save(model, torch_path)
    print(f"âœ… PyTorchæ¨¡å‹å·²ä¿å­˜: {torch_path}")
    
    # æ ¹æ®GitHubæ–‡æ¡£ï¼Œå°è¯•ä½¿ç”¨ä¿å­˜çš„æ¨¡å‹ç›´æ¥å¯¼å‡ºONNX
    print("ğŸ“¦ å°è¯•ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç›´æ¥å¯¼å‡ºONNX...")
    try:
        # å®‰è£…ONNXå¯¼å‡ºä¾èµ–
        import subprocess
        print("å®‰è£…ONNXå¯¼å‡ºä¾èµ–...")
        subprocess.run(["pip", "install", "rfdetr[onnxexport]"], check=True)
        
        # ç›´æ¥ä»è®­ç»ƒå¥½çš„æ¨¡å‹å¯¼å‡ºï¼Œè€Œä¸æ˜¯åŠ è½½ä¿å­˜çš„æ¨¡å‹
        print("å¼€å§‹å¯¼å‡ºONNX...")
        onnx_path = os.path.join(OUTPUT_DIR, "rf-detr.onnx")
        
        # è¿™é‡Œä½¿ç”¨åŸå§‹æ¨¡å‹ç›´æ¥å¯¼å‡ºï¼Œé¿å…é‡æ–°åŠ è½½
        model.export(output_path=onnx_path, device="cpu")
        print(f"âœ… ONNXå¯¼å‡ºæˆåŠŸ: {onnx_path}")
    except Exception as e:
        print(f"âŒ ç›´æ¥å¯¼å‡ºONNXå¤±è´¥: {str(e)}")
        
        # ä½¿ç”¨å®‰å…¨æ¨¡å¼åŠ è½½æ¨¡å‹
        try:
            print("å°è¯•ä½¿ç”¨å®‰å…¨æ¨¡å¼åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹...")
            
            # åˆ›å»ºå•ç‹¬çš„å¯¼å‡ºè„šæœ¬ï¼Œè§£å†³å®‰å…¨åŠ è½½é—®é¢˜
            export_script = f"""
import os
import torch
import sys
from rfdetr import RFDETRBase, RFDETR
from rfdetr.detr import RFDETRBase as RFDETRBaseClass
from torch.serialization import add_safe_globals

# ç¦ç”¨MPSè®¾å¤‡
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
os.environ["PYTORCH_NO_MPS"] = "1"

# æ·»åŠ å®‰å…¨åŠ è½½çš„ç±»
add_safe_globals([RFDETRBaseClass, RFDETR, RFDETRBase])

# åŠ è½½æ¨¡å‹ï¼Œæ˜¾å¼è®¾ç½®weights_only=False
try:
    print("ä½¿ç”¨å®‰å…¨æ–¹å¼åŠ è½½æ¨¡å‹...")
    model_path = "{torch_path}"
    
    # é¦–å…ˆå°è¯•åŠ è½½æ¨¡å‹æ¶æ„
    empty_model = RFDETRBase(
        encoder="dinov2_windowed_small",
        resolution=392,
        multi_scale=False,
        expanded_scales=False,
        dec_layers=2,
        dim_feedforward=1024,
        hidden_dim=192,
        sa_nheads=4,
        ca_nheads=8,
        num_queries=100,
        pretrain_weights=None,
        force_no_pretrain=True
    )
    
    # åŠ è½½æ¨¡å‹æƒé‡åˆ°ç©ºæ¨¡å‹
    loaded_dict = torch.load(model_path, weights_only=False)
    
    # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–æ¨¡å‹
    # æ–¹æ³•1: å¦‚æœsaved_modelæ˜¯state_dictæ ¼å¼
    if isinstance(loaded_dict, dict) and "model" in loaded_dict:
        empty_model.load_state_dict(loaded_dict["model"])
        model = empty_model
    else:
        # æ–¹æ³•2: ç›´æ¥ä½¿ç”¨åŠ è½½çš„æ¨¡å‹
        model = loaded_dict
    
    # å¯¼å‡ºONNX
    print("å¼€å§‹å¯¼å‡ºONNX...")
    onnx_path = "{os.path.join(OUTPUT_DIR, 'rf-detr.onnx')}"
    model.export(output_path=onnx_path, device="cpu")
    print(f"âœ… ONNXå¯¼å‡ºæˆåŠŸ: {{onnx_path}}")
    sys.exit(0)
except Exception as e:
    print(f"âŒ å¯¼å‡ºå¤±è´¥: {{str(e)}}")
    sys.exit(1)
"""
            
            with open("export_onnx.py", "w") as f:
                f.write(export_script)
            
            # ä½¿ç”¨Pythonè§£é‡Šå™¨è¿è¡Œ
            print("å¯åŠ¨å¯¼å‡ºè¿›ç¨‹...")
            result = subprocess.run(["python", "export_onnx.py"], capture_output=True, text=True)
            
            if result.returncode == 0:
                print(result.stdout)
            else:
                print(f"å¯¼å‡ºå¤±è´¥:\n{result.stderr}")
                print(f"è¯¦ç»†ä¿¡æ¯:\n{result.stdout}")
                print("è¯·ä½¿ç”¨å·²ä¿å­˜çš„PyTorchæ¨¡å‹(.pth)æ–‡ä»¶")
        except Exception as e:
            print(f"âŒ å°è¯•åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            print("è¯·ä½¿ç”¨å·²ä¿å­˜çš„PyTorchæ¨¡å‹(.pth)æ–‡ä»¶è¿›è¡Œæ¨ç†")

if __name__ == "__main__":
    main()
